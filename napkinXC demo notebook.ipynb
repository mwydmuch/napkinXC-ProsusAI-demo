{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# napkinXC demo @ Prosus Global AI Marketplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "napkinXC is an extremely simple and fast library for extreme multi-class and multi-label classification. It allows to train a classifier for very large datasets in few lines of code with minimal resources. This notebooks demonstraits how yo train and evaluate extreme multi-label classifier using napkinXC.\n",
    "\n",
    "napkinXC GitHub: [https://github.com/mwydmuch/napkinXC](https://github.com/mwydmuch/napkinXC)\n",
    "\n",
    "napkinXC authors:\n",
    "- Marek Wydmuch (Data Scientist @ OLX Group, PhD Student @ Poznań University of Techonology)\n",
    "- Kalina Jasinska-Kobus (Research Engineer @ Allegro ML Reaserch, PhD Student @ Poznań University of Techonology)\n",
    "- Krzysztof Dembczynski (Senior Research Scientist @ Yahoo! Research)\n",
    "- Robert Busa-Fekete (Research Scientist @ Google Research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: napkinxc in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (0.4.0)\r\n",
      "Requirement already satisfied: numpy in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (from napkinxc) (1.18.4)\r\n",
      "Requirement already satisfied: sklearn in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (from napkinxc) (0.0)\r\n",
      "Requirement already satisfied: scipy in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (from napkinxc) (1.3.3)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (from sklearn->napkinxc) (0.22.2.post1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/mwydmuch/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn->napkinxc) (0.14.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install napkinxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model Name: MacBook Pro\r\n",
      "      Model Identifier: MacBookPro15,2\r\n",
      "      Processor Name: Quad-Core Intel Core i7\r\n",
      "      Processor Speed: 2,7 GHz\r\n",
      "      Number of Processors: 1\r\n",
      "      Total Number of Cores: 4\r\n",
      "      L2 Cache (per Core): 256 KB\r\n",
      "      L3 Cache: 8 MB\r\n",
      "      Hyper-Threading Technology: Enabled\r\n",
      "      Memory: 16 GB\r\n"
     ]
    }
   ],
   "source": [
    "!system_profiler SPHardwareDataType | head -n 14 | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark dataset\n",
    "\n",
    "Let's use `load_dataset` function to load AmazonCat-13K dataset, one of the benchmarks datasets from [XML Repository](http://manikvarma.org/downloads/XC/XMLRepository.html).\n",
    "\n",
    "The task in AmazonCat-13K datasets is to assign topics to books from the Amazon catalog based on their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napkinxc.datasets import load_dataset\n",
    "\n",
    "X_train, Y_train = load_dataset(\"amazoncat-13k\", \"train\", format='tf-idf')\n",
    "X_test, Y_test = load_dataset(\"amazoncat-13k\", \"test\", format='tf-idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the most basic statistics of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 203882\n",
      "labels: 13329.0\n",
      "train data points: 1186239\n",
      "test data points: 306782\n",
      "avg. labels per data point: 5.04066971327026\n"
     ]
    }
   ],
   "source": [
    "print(\"features:\", X_train.shape[1])\n",
    "print(\"labels:\", max([max((0,) + y) for y in Y_train]))\n",
    "print(\"train data points:\", X_train.shape[0])\n",
    "print(\"test data points:\", X_test.shape[0])\n",
    "print(\"avg. labels per data point:\", sum([len(y) for y in Y_train]) / X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Let's import Probabilistic Label Trees (`PLT`) model from napkinXC and construct it.\n",
    "Because napkinXC uses a local drive for storing unused data to optimize memory footprint during the training, the constructor requires a path to the model directory as the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napkinxc.models import PLT\n",
    "\n",
    "plt = PLT(\"amazoncat-model\", optimizer=\"adagrad\", epochs=1, threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fit the model on the training data. napkinXC follows sklearn conventions for methods names.\n",
    "Currently, X can be a dense Numpy or sparse Scipy CSR matrix, while Y can be a scipy sparse matrix or list of lists with positive labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 94.39669394493103 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_start = time.time()\n",
    "plt.fit(X_train, Y_train)\n",
    "train_end = time.time()\n",
    "print(\"train time:\", train_end - train_start, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Now let's evaluate our model. We are first predicting one label with the highest probability for each data point in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time: 26.69292902946472 s\n",
      "prediction time / data point: 0.0870094367644279 ms\n"
     ]
    }
   ],
   "source": [
    "prediction_start = time.time()\n",
    "Y_pred = plt.predict(X_test, top_k=1)\n",
    "prediction_end = time.time()\n",
    "print(\"prediction time:\", prediction_end - prediction_start, \"s\")\n",
    "print(\"prediction time / data point:\", (prediction_end - prediction_start) / len(Y_pred) * 1000, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model's predictive performance using `precision_at_k` (precision at k-th place), one of the measures implemented in napkinXC.\n",
    "\n",
    "Precision at k is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{p}@k(\\boldsymbol{y}, \\boldsymbol{x}, \\boldsymbol{h}) = \\frac{1}{k} \\sum_{j \\in \\hat {\\mathcal{Y}_k}} [[ y_j = 1 ]],\n",
    "$$\n",
    "\n",
    "where $\\hat {\\mathcal{Y}_k}$ is a set of $k$ labels predicted by classfier $\\boldsymbol{h}$ for $\\boldsymbol{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@1: 0.9308792562797035\n"
     ]
    }
   ],
   "source": [
    "from napkinxc.measures import precision_at_k\n",
    "\n",
    "print(\"p@1:\", precision_at_k(Y_test, Y_pred, k=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current SOTA methods based on transformers language models obtain ~0.95 on this dataset. However, they require hours of training on much larger machines. Using napkinXC, you can train model performing. \n",
    "\n",
    "Training napkinXC PLT model for Amazon-3M dataset, product to product recommendation task with 1.7 mln of training examples and 2.8 mln of labels takes ~2h on a similar machine. It achieves ~0.47 almost out of the box. The current SOTA achieves ~0.50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### napkinXC allows you to quickly apply extreme classification to you problem!\n",
    "### napkinXC  is the only library available that allows online prediction within milliseconds!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "napkinXC is currently under heavy development, we plan to add a possibility to use any type of binary classifier from Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
